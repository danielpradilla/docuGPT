{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "import streamlit as st\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import OpenAI\n",
    "import os\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_link(link):\n",
    "    loaders = UnstructuredURLLoader(urls=[link])\n",
    "    data = loaders.load()\n",
    "    return data\n",
    "\n",
    "def split_text(data):\n",
    "    text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(data)\n",
    "    return docs\n",
    "\n",
    "def get_embeddings(docs): # will get embeddings from docs and then store them in a vector database\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorSpace_openAI = FAISS.from_documents(docs, embeddings)\n",
    "    return vectorSpace_openAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 14\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "loaders = UnstructuredURLLoader(urls=['https://mypy.readthedocs.io/'])\n",
    "data = loaders.load()\n",
    "text_splitter = CharacterTextSplitter(separator='\\n', chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(f'Number of documents: {len(docs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortlisted_docs = docs[:4]\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs, embeddings,\n",
    "    persist_directory='vectorstore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info=[\n",
    "    AttributeInfo(\n",
    "        name=\"rating\",\n",
    "        description=\"A 1-10 rating for the movie\",\n",
    "        type=\"float\"\n",
    "    ),\n",
    "]\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), verbose=True, chain_type=\"stuff\")\n",
    "\n",
    "\n",
    "# document_content_description = \"MyPy documentation\"\n",
    "# llm = OpenAI(temperature=0)\n",
    "# retriever = SelfQueryRetriever.from_llm(llm, vectorstore, document_content_description, metadata_field_info, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The documentation covers topics related to type inference, explicit types for variables and collections, compatibility of container types, context in type inference, silencing type errors, kinds of types, class types, the Any type, tuple types, callable types (and lambdas), union types, optional types and the None type, disabling strict optional checking, type aliases, named tuples, the type of class objects, generators, class basics, instance and class attributes, annotating __init__ methods, class attribute annotations, overriding statically typed methods, abstract base classes and multiple inheritance, slots, annotation issues at runtime, string literal types and type comments, future annotations import (PEP 563), typing.TYPE_CHECKING, class name forward references, import cycles, using classes that are generic in stubs but not at runtime, using types defined in stubs but not at runtime, using generic builtins, using X | Y syntax for Unions, using new additions to the typing module, protocols and structural subtyping, and predefined protocols.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever.get_relevant_documents(\"What is the content of the documentation?\")\n",
    "\n",
    "query = \"What is the content of the documentation?\"\n",
    "# chain({\"question\": query}, return_only_outputs=True)\n",
    "chain.run(query)\n",
    "\n",
    "# chain({\"question\": \"What is the content of the documentation?\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
